{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1583820"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.fileids()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(movie_reviews.words())\n",
    "import string\n",
    "text_filtered = text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then remove the stopwords and then make all words lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "tokens = word_tokenize(text_filtered)\n",
    "word_filtered = [w.lower() for w in tokens if w not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use FreqDist() function on NLTK to have a dictionary of frequency of apperance of word in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict = nltk.FreqDist(word_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('film', 9519), ('one', 5853), ('movie', 5774), ('like', 3690), ('even', 2565), ('good', 2411), ('time', 2411), ('story', 2170), ('would', 2110), ('much', 2050), ('character', 2020), ('also', 1967), ('get', 1949), ('two', 1912), ('well', 1906)]\n"
     ]
    }
   ],
   "source": [
    "print(counter_dict.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [(list(movie_reviews.words(fileid)), category)\n",
    "        for category in movie_reviews.categories()\n",
    "        for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above section of the code can be translated to: \n",
    "\n",
    "In every category (we have either pos or neg), take the entire file IDs (every review has own ID), \n",
    "\n",
    "Store the word_tokenized version (list of words) for the file ID, and then followed by the positive or negative label in one big list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list containing 3000 most frequent words in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_features = [w[0] for w in counter_dict.most_common(3000)]\n",
    "word_features = ['outstanding',\n",
    "'schumacher',\n",
    "'mulan',\n",
    "'ludicrous',\n",
    "'finest',\n",
    "'welles',\n",
    "'jolie',\n",
    "'embarrassing',\n",
    "'beautifully',\n",
    "'religion',\n",
    "'freddie',\n",
    "'prinze',\n",
    "'gon',\n",
    "'wasted',\n",
    "'lame',\n",
    "'anna',\n",
    "'ridiculous',\n",
    "'wonderfully',\n",
    "'garbage',\n",
    "'idiotic',\n",
    "'mature',\n",
    "'alicia',\n",
    "'anger',\n",
    "'breathtaking',\n",
    "'sandler',\n",
    "'awful',\n",
    "'lebowski',\n",
    "'refreshing',\n",
    "'whatsoever',\n",
    "'inept',\n",
    "'uninteresting',\n",
    "'bore',\n",
    "'tucker',\n",
    "'painfully',\n",
    "'waste',\n",
    "'jedi',\n",
    "'laughable',\n",
    "'ordinary',\n",
    "'flynt',\n",
    "'bland',\n",
    "'sat',\n",
    "'henstridge',\n",
    "'diaz',\n",
    "'damon',\n",
    "'nomination',\n",
    "'dull',\n",
    "'unfunny',\n",
    "'lifeless',\n",
    "'terrific',\n",
    "'poorly',\n",
    "'badly',\n",
    "'hanks',\n",
    "'random',\n",
    "'damme',\n",
    "'fincher',\n",
    "'rape',\n",
    "'snow',\n",
    "'superb',\n",
    "'worst',\n",
    "'boring',\n",
    "'era',\n",
    "'stupid',\n",
    "'reese',\n",
    "'traditional',\n",
    "'anywhere',\n",
    "'inane',\n",
    "'allows',\n",
    "'obi',\n",
    "'memorable',\n",
    "'decades',\n",
    "'friendship',\n",
    "'skip',\n",
    "'masterpiece',\n",
    "'terrible',\n",
    "'satisfying',\n",
    "'freedom',\n",
    "'designer',\n",
    "'portrayed',\n",
    "'spacey',\n",
    "'sports',\n",
    "'fits',\n",
    "'snake',\n",
    "'frankly',\n",
    "'fantastic',\n",
    "'innocence',\n",
    "'subtle',\n",
    "'extraordinary',\n",
    "'pointless',\n",
    "'contrast',\n",
    "'remarkable',\n",
    "'jackal',\n",
    "'italian',\n",
    "'terribly',\n",
    "'realistic',\n",
    "'understanding',\n",
    "'insult',\n",
    "'visually',\n",
    "'mess',\n",
    "'remake',\n",
    "'banderas',\n",
    "'tribe',\n",
    "'lethal',\n",
    "'colors',\n",
    "'derek',\n",
    "'jar',\n",
    "'brilliantly',\n",
    "'delight',\n",
    "'delightful',\n",
    "'joy',\n",
    "'na',\n",
    "'notch',\n",
    "'excellent',\n",
    "'patch',\n",
    "'tedious',\n",
    "'portrayal',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outstanding',\n",
       " 'schumacher',\n",
       " 'mulan',\n",
       " 'ludicrous',\n",
       " 'finest',\n",
       " 'welles',\n",
       " 'jolie',\n",
       " 'embarrassing',\n",
       " 'beautifully',\n",
       " 'religion',\n",
       " 'freddie',\n",
       " 'prinze',\n",
       " 'gon',\n",
       " 'wasted',\n",
       " 'lame',\n",
       " 'anna',\n",
       " 'ridiculous',\n",
       " 'wonderfully',\n",
       " 'garbage',\n",
       " 'idiotic',\n",
       " 'mature',\n",
       " 'alicia',\n",
       " 'anger',\n",
       " 'breathtaking',\n",
       " 'sandler',\n",
       " 'awful',\n",
       " 'lebowski',\n",
       " 'refreshing',\n",
       " 'whatsoever',\n",
       " 'inept',\n",
       " 'uninteresting',\n",
       " 'bore',\n",
       " 'tucker',\n",
       " 'painfully',\n",
       " 'waste',\n",
       " 'jedi',\n",
       " 'laughable',\n",
       " 'ordinary',\n",
       " 'flynt',\n",
       " 'bland',\n",
       " 'sat',\n",
       " 'henstridge',\n",
       " 'diaz',\n",
       " 'damon',\n",
       " 'nomination',\n",
       " 'dull',\n",
       " 'unfunny',\n",
       " 'lifeless',\n",
       " 'terrific',\n",
       " 'poorly',\n",
       " 'badly',\n",
       " 'hanks',\n",
       " 'random',\n",
       " 'damme',\n",
       " 'fincher',\n",
       " 'rape',\n",
       " 'snow',\n",
       " 'superb',\n",
       " 'worst',\n",
       " 'boring',\n",
       " 'era',\n",
       " 'stupid',\n",
       " 'reese',\n",
       " 'traditional',\n",
       " 'anywhere',\n",
       " 'inane',\n",
       " 'allows',\n",
       " 'obi',\n",
       " 'memorable',\n",
       " 'decades',\n",
       " 'friendship',\n",
       " 'skip',\n",
       " 'masterpiece',\n",
       " 'terrible',\n",
       " 'satisfying',\n",
       " 'freedom',\n",
       " 'designer',\n",
       " 'portrayed',\n",
       " 'spacey',\n",
       " 'sports',\n",
       " 'fits',\n",
       " 'snake',\n",
       " 'frankly',\n",
       " 'fantastic',\n",
       " 'innocence',\n",
       " 'subtle',\n",
       " 'extraordinary',\n",
       " 'pointless',\n",
       " 'contrast',\n",
       " 'remarkable',\n",
       " 'jackal',\n",
       " 'italian',\n",
       " 'terribly',\n",
       " 'realistic',\n",
       " 'understanding',\n",
       " 'insult',\n",
       " 'visually',\n",
       " 'mess',\n",
       " 'remake',\n",
       " 'banderas',\n",
       " 'tribe',\n",
       " 'lethal',\n",
       " 'colors',\n",
       " 'derek',\n",
       " 'jar',\n",
       " 'brilliantly',\n",
       " 'delight',\n",
       " 'delightful',\n",
       " 'joy',\n",
       " 'na',\n",
       " 'notch',\n",
       " 'excellent',\n",
       " 'patch',\n",
       " 'tedious',\n",
       " 'portrayal']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider existence/non-existence of these words in each of reviews as features by defining the following function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_features(doc):\n",
    "    words = set(doc)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the function on the first review (docs was defined before as the list of tuples containing reviews with their corresponding sentiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_features(docs[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are only the first 14 words in the word_features variable (containing 3000 words) for the first review. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the function to all the reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = [(search_features(doc), category) for (doc, category) in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first element from featureset and explore the component inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outstanding': False, 'schumacher': False, 'mulan': False, 'ludicrous': False, 'finest': False, 'welles': False, 'jolie': False, 'embarrassing': False, 'beautifully': False, 'religion': False, 'freddie': False, 'prinze': False, 'gon': False, 'wasted': False, 'lame': False, 'anna': False, 'ridiculous': False, 'wonderfully': False, 'garbage': False, 'idiotic': False, 'mature': False, 'alicia': False, 'anger': False, 'breathtaking': False, 'sandler': False, 'awful': False, 'lebowski': False, 'refreshing': False, 'whatsoever': False, 'inept': False, 'uninteresting': False, 'bore': False, 'tucker': False, 'painfully': False, 'waste': False, 'jedi': False, 'laughable': False, 'ordinary': False, 'flynt': False, 'bland': False, 'sat': False, 'henstridge': False, 'diaz': False, 'damon': False, 'nomination': False, 'dull': False, 'unfunny': False, 'lifeless': False, 'terrific': False, 'poorly': False, 'badly': False, 'hanks': False, 'random': False, 'damme': False, 'fincher': False, 'rape': False, 'snow': False, 'superb': False, 'worst': False, 'boring': False, 'era': False, 'stupid': False, 'reese': False, 'traditional': False, 'anywhere': False, 'inane': False, 'allows': False, 'obi': False, 'memorable': False, 'decades': False, 'friendship': False, 'skip': True, 'masterpiece': False, 'terrible': False, 'satisfying': False, 'freedom': False, 'designer': False, 'portrayed': False, 'spacey': False, 'sports': False, 'fits': False, 'snake': False, 'frankly': False, 'fantastic': False, 'innocence': False, 'subtle': False, 'extraordinary': False, 'pointless': False, 'contrast': False, 'remarkable': False, 'jackal': False, 'italian': False, 'terribly': True, 'realistic': False, 'understanding': True, 'insult': False, 'visually': False, 'mess': True, 'remake': False, 'banderas': False, 'tribe': False, 'lethal': False, 'colors': False, 'derek': False, 'jar': False, 'brilliantly': False, 'delight': False, 'delightful': False, 'joy': False, 'na': False, 'notch': False, 'excellent': False, 'patch': False, 'tedious': False, 'portrayal': False}\n"
     ]
    }
   ],
   "source": [
    "print(featureset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can train and test our algorithm, we should first split our data into training and test sets. \n",
    "\n",
    "Since our dataset has been shuffled, the first 1600 shuffled reviews (consisting both positive and negative reviews) will be used as the training set. \n",
    "\n",
    "The remaining 20% (400 reviews) will be used to perform the test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = featureset[:1600]\n",
    "testing_set = featureset[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "negative :  62.5 %\n",
      "positive :  37.5 %\n",
      "Testing set\n",
      "negative :  0.0 %\n",
      "positive :  100.0 %\n"
     ]
    }
   ],
   "source": [
    "def count_features(list_item):\n",
    "    negative_count = 0\n",
    "    positive_count = 0\n",
    "    for value in list_item:\n",
    "        if value[1] == 'neg':\n",
    "            negative_count += 1\n",
    "        elif value[1] == 'pos':\n",
    "            positive_count += 1\n",
    "\n",
    "    total = len(list_item)\n",
    "\n",
    "    print('negative : ', negative_count / total * 100, '%')\n",
    "    print('positive : ', positive_count / total * 100, '%')\n",
    "\n",
    "\n",
    "print('Training set')\n",
    "count_features(training_set)\n",
    "print('Testing set')\n",
    "count_features(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = featureset[:1600]\n",
    "testing_set = featureset[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "negative :  50.0625 %\n",
      "positive :  49.9375 %\n",
      "Testing set\n",
      "negative :  49.75 %\n",
      "positive :  50.24999999999999 %\n"
     ]
    }
   ],
   "source": [
    "def count_features(list_item):\n",
    "    negative_count = 0\n",
    "    positive_count = 0\n",
    "    for value in list_item:\n",
    "        if value[1] == 'neg':\n",
    "            negative_count += 1\n",
    "        elif value[1] == 'pos':\n",
    "            positive_count += 1\n",
    "\n",
    "    total = len(list_item)\n",
    "\n",
    "    print('negative : ', negative_count / total * 100, '%')\n",
    "    print('positive : ', positive_count / total * 100, '%')\n",
    "\n",
    "\n",
    "print('Training set')\n",
    "count_features(training_set)\n",
    "print('Testing set')\n",
    "count_features(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is labeled, this process is referred to as supervised learning.\n",
    "\n",
    "We will use Naive Bayes on NLTK as the algorithm as it is a very popular algorithm for text classification.\n",
    "\n",
    "We create the instance of the model and then train it on the training set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the model accuracy by testing it on the testing set. \n",
    "\n",
    "We can use classify.accuracy() function on nltk to determine the accuracy of a trained model.\n",
    "\n",
    "It needs the trained model instance and the training test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier's accuracy for testing_set is: 80.75\n",
      "classifier's accuracy for training_set is : 82.25\n"
     ]
    }
   ],
   "source": [
    "print(\"classifier's accuracy for testing_set is: {}\" .format(nltk.classify.accuracy(classifier, testing_set)*100))\n",
    "print(\"classifier's accuracy for training_set is : {}\" .format(nltk.classify.accuracy(classifier, training_set)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most informative words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can take it a step further to see what the most valuable words are when it comes to positive or negative reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 idiotic = True              neg : pos    =     15.6 : 1.0\n",
      "               ludicrous = True              neg : pos    =     14.6 : 1.0\n",
      "             outstanding = True              pos : neg    =      9.6 : 1.0\n",
      "                     obi = True              pos : neg    =      7.7 : 1.0\n",
      "                  finest = True              pos : neg    =      7.7 : 1.0\n",
      "                religion = True              pos : neg    =      7.0 : 1.0\n",
      "                  poorly = True              neg : pos    =      7.0 : 1.0\n",
      "            breathtaking = True              pos : neg    =      6.8 : 1.0\n",
      "               painfully = True              neg : pos    =      6.1 : 1.0\n",
      "                  wasted = True              neg : pos    =      6.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_classifier = open(\"naive_bayes_model.pkl\", \"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_f = open(\"naive_bayes_model.pkl\", \"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'web_tokenize' from 'nltk' (c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m custom_review \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI hated the restaurant. It was a disaster eating there. Poor service, arrogant waiters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m web_tokenize\n\u001b[0;32m      4\u001b[0m custom_review_tokens \u001b[38;5;241m=\u001b[39m word_tokenize(custom_review)\n\u001b[0;32m      5\u001b[0m custom_review_set \u001b[38;5;241m=\u001b[39m document_features(custom_review_tokens)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'web_tokenize' from 'nltk' (c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py)"
     ]
    }
   ],
   "source": [
    "custom_review = \"I hated the restaurant. It was a disaster eating there. Poor service, arrogant waiters.\"\n",
    "\n",
    "from nltk import web_tokenize\n",
    "\n",
    "custom_review_tokens = word_tokenize(custom_review)\n",
    "custom_review_set = document_features(custom_review_tokens)\n",
    "print(classifier.clssify(custom_review_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_review_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prob_result \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mprob_classify(custom_review_set)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(prob_result\u001b[38;5;241m.\u001b[39mmax())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(prob_result\u001b[38;5;241m.\u001b[39mprob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'custom_review_set' is not defined"
     ]
    }
   ],
   "source": [
    "prob_result = classifier.prob_classify(custom_review_set)\n",
    "print(prob_result.max())\n",
    "print(prob_result.prob('pos'))\n",
    "print(prob_result.prob('neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
